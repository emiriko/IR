Background knowledge is an important factor in privacy preserving data
publishing. Distribution-based background knowledge is one of the well studied
background knowledge. However, to the best of our knowledge, there is no
existing work considering the distribution-based background knowledge in the
worst case scenario, by which we mean that the adversary has accurate knowledge
about the distribution of sensitive values according to some tuple attributes.
Considering this worst case scenario is essential because we cannot overlook
any breaching possibility. In this paper, we propose an algorithm to anonymize
dataset in order to protect individual privacy by considering this background
knowledge. We prove that the anonymized datasets generated by our proposed
algorithm protects individual privacy. Our empirical studies show that our
method preserves high utility for the published data at the same time.