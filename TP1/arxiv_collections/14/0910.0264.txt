We use the $f-divergence$ also called relative entropy as a measure of
diversity between probability densities and review its basic properties. In the
sequence we define a few objects which capture relevant information from the
sample of a Markov Chain to be used in the definition of a couple of estimators
i.e. the Local Dependency Level and Global Dependency Level for a Markov chain
sample. After exploring their properties we propose a new estimator for the
Markov chain order. Finally we show a few tables containing numerical
simulation results, comparing the performance of the new estimator with the
well known and already established AIC and BIC estimators.