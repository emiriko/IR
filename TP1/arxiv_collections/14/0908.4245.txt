Precision measurements of neutron star radii can provide a powerful probe of
the properties of cold matter beyond nuclear density. Beginning in the late
1970s it was proposed that the radius could be obtained from the apparent or
inferred emitting area during the decay portions of thermonuclear (type I)
X-ray bursts. However, this apparent area is generally not constant, preventing
reliable measurement of the source radius. Here we report for the first time a
correlation between the variation of the inferred area and the burst
properties, measured in a sample of almost 900 bursts from 43 sources. We found
that the rate of change of the inferred area during decay is anticorrelated
with the burst decay duration. A Spearman rank correlation test shows that this
relation is significant at the <10^{-45} level for our entire sample, and at
the 7x10^{-37} level for the 625 bursts without photospheric radius expansion.
This anticorrelation is also highly significant for individual sources
exhibiting a wide range of burst durations, such as 4U 1636-536 and Aql X-1. We
suggest that variations in the colour factor, which relates the colour
temperature resulted from the scattering in the neutron star atmosphere to the
effective temperature of the burning layer, may explain the correlation. This
in turn implies significant variations in the composition of the atmosphere
between bursts with long and short durations.