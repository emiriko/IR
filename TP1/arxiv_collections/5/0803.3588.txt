We study the dynamics of Bose-Einstein condensates in time-dependent
microtraps for the purpose of understanding the influence of the mean field
interaction on the performance of interferometers. We identify conditions where
the non-linearity due to atom interactions increases the sensitivity of
interferometers to a phase shift. This feature is connected with the adiabatic
generation of a dark soliton. We analyze the robustness of this phenomenon with
respect to thermal fluctuations, due to excited near fields in an
electromagnetic surface trap.