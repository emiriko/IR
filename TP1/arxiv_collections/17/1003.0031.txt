We show that the natural scaling of measurement for a particular problem
defines the most likely probability distribution of observations taken from
that measurement scale. Our approach extends the method of maximum entropy to
use measurement scale as a type of information constraint. We argue that a very
common measurement scale is linear at small magnitudes grading into logarithmic
at large magnitudes, leading to observations that often follow Student's
probability distribution which has a Gaussian shape for small fluctuations from
the mean and a power law shape for large fluctuations from the mean. An inverse
scaling often arises in which measures naturally grade from logarithmic to
linear as one moves from small to large magnitudes, leading to observations
that often follow a gamma probability distribution. A gamma distribution has a
power law shape for small magnitudes and an exponential shape for large
magnitudes. The two measurement scales are natural inverses connected by the
Laplace integral transform. This inversion connects the two major scaling
patterns commonly found in nature. We also show that superstatistics is a
special case of an integral transform, and thus can be understood as a
particular way in which to change the scale of measurement. Incorporating
information about measurement scale into maximum entropy provides a general
approach to the relations between measurement, information and probability.