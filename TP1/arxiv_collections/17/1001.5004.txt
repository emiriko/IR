Unlike the Probability Theory based on additivity, Statistical Inference
seems to hesitate between "Additivity" and a so-called "Maxitivity" approach.
After a brief overview of three types of principles for any (parametric)
statistical theory and the proof that these principles are mutually exclusive,
the paper shows that two kinds of support measures are conceivable, an additive
one and a maxitive one (based on maximization operators). Unfortunately, none
of them is able to cope with the ignorance part of the statistical experiment
and, in the meantime, with the partial information given through the structure
of the data. To conclude, the author promotes the combined use of both
approaches, as an efficient middle-of-the-road position for the statistician.