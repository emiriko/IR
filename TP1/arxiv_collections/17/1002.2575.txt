We investigate the dependence on length of optical fibres used in astronomy,
especially the focal ratio degradation (FRD) which places constraints on the
performance of fibre-fed spectrographs used for multiplexed spectroscopy. To
this end we present a modified version of the FRD model proposed by Carrasco
and Parry \cite{Carrasco1994} to quantify the the number of scattering defects
within an optical fibre using a single parameter. The model predicts many
trends which are seen experimentally, for example, a decrease in FRD as core
diameter increases, and also as wavelength increases. However the model also
predicts a strong dependence on FRD with length that is not seen
experimentally. By adapting the single fibre model to include a second fibre,
we can quantify the amount of FRD due to stress caused by the method of
termination. By fitting the model to experimental data we find that polishing
the fibre causes more stress to be induced in the end of the fibre compared to
a simple cleave technique. We estimate that the number of scattering defects
caused by polishing is approximately double that produced by cleaving. By
placing limits on the end-effect, the model can be used to estimate the
residual-length dependence in very long fibres, such as those required for
Extremely Large Telescopes (ELTs), without having to carry out costly
experiments. We also use our data to compare different methods of fibre
termination.