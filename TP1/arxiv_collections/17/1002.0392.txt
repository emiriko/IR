Nowadays, random telegraph signals play an important role in integrated
circuit performance variability, leading for instance to failures in memory
circuits. This problem is related to the successive captures and emissions of
electrons at the many traps stochastically distributed at the silicon-oxide
(Si-SiO2) interface of MOS transistors. In this paper we propose a novel
analytical and numerical approach to statistically describe the fluctuations of
current due to random telegraph signal in time domain. Our results include two
distinct situations: when the density of interface trap density is uniform in
energy, and when it is an u-shape curve as prescribed in literature, here
described as simple quadratic function. We establish formulas for relative
error as function of the parameters related to capture and emission
probabilities. For a complete analysis experimental u-shape curves are used and
compared with the theoretical aproach.