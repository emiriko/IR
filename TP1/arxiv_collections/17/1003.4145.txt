Previous work has shown that robot navigation systems that employ an
architecture based upon the idiotypic network theory of the immune system have
an advantage over control techniques that rely on reinforcement learning only.
This is thought to be a result of intelligent behaviour selection on the part
of the idiotypic robot. In this paper an attempt is made to imitate idiotypic
dynamics by creating controllers that use reinforcement with a number of
different probabilistic schemes to select robot behaviour. The aims are to show
that the idiotypic system is not merely performing some kind of periodic random
behaviour selection, and to try to gain further insight into the processes that
govern the idiotypic mechanism. Trials are carried out using simulated Pioneer
robots that undertake navigation exercises. Results show that a scheme that
boosts the probability of selecting highly-ranked alternative behaviours to 50%
during stall conditions comes closest to achieving the properties of the
idiotypic system, but remains unable to match it in terms of all round
performance.