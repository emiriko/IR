We recently reported that the simple genetic algorithm (SGA) is capable of
performing a remarkable form of sublinear computation which has a
straightforward connection with the general problem of interacting attributes
in data-mining. In this paper we explain how the SGA can leverage this
computational proficiency to perform efficient adaptation on a broad class of
fitness functions. Based on the relative ease with which a practical fitness
function might belong to this broad class, we submit a new hypothesis about the
workings of genetic algorithms. We explain why our hypothesis is superior to
the building block hypothesis, and, by way of empirical validation, we present
the results of an experiment in which the use of a simple mechanism called
clamping dramatically improved the performance of an SGA with uniform crossover
on large, randomly generated instances of the MAX 3-SAT problem.