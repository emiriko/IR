We study the error of reversible Markov chain Monte Carlo methods for
approximating the expectation of a function. Explicit error bounds with respect
to different norms of the function are proven. By the estimation the well known
asymptotical limit of the error is attained, i.e. there is no gap between the
estimate and the asymptotical behavior. We discuss the dependence of the error
on a burn-in of the Markov chain. Furthermore we suggest and justify a specific
burn-in for optimizing the algorithm.