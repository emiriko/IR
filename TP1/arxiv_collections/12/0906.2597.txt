We constrain the distance of the Gamma-Ray Burst (GRB) prompt emission site
from the explosion centre, R, by determining the location of the electron's
self absorption frequency in the GRB prompt optical-to-X/gamma-ray spectral
energy distribution, assuming that the optical and the gamma-ray emissions are
among the same synchrotron radiation continuum of a group of hot electrons. All
possible spectral regimes are considered in our analysis. The method has only
two assumed parameters, namely, the bulk Lorentz factor of the emitting source
Gamma, and the magnetic field strength B in the emission region (with a weak
dependence). We identify a small sample of 4 bursts that satisfy the following
three criteria: (1) they all have simultaneous optical and gamma-ray detections
in multiple observational time intervals; (2) they all show temporal
correlations between the optical and gamma-ray light curves; and (3) the
optical emission is consistent with belonging to the same spectral component as
the gamma-ray emission. For all the time intervals of these 4 bursts, it is
inferred that R \geq 10^{14} (Gamma/300)^{3/4} (B/10^5 Gauss)^{1/4} cm. For a
small fraction of the sample, the constraint can be pinned down to R \approx
10^{14} - 10^{15} cm for Gamma ~ 300. For a second sample of bursts with prompt
optical non-detections, only upper limits on R can be obtained. We find no
inconsistency between the R-constraints for this non-detection sample and those
for the detection sample.