We investigate dynamical systems characterized by a time series of distinct
semi-stable activity patterns, as they are observed in cortical neural activity
patterns. We propose and discuss a general mechanism allowing for an adiabatic
continuation between attractor networks and a specific adjoined transient-state
network, which is strictly dissipative. Dynamical systems with transient states
retain functionality when their working point is autoregulated; avoiding
prolonged periods of stasis or drifting into a regime of rapid fluctuations. We
show, within a continuous-time neural network model, that a single local
updating rule for online learning allows simultaneously (i) for information
storage via unsupervised Hebbian-type learning, (ii) for adaptive regulation of
the working point and (iii) for the suppression of runaway synaptic growth.
Simulation results are presented; the spontaneous breaking of time-reversal
symmetry and link symmetry are discussed.