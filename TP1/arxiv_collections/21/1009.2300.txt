We propose the Bayesian adaptive Lasso (BaLasso) for variable selection and
coefficient estimation in linear regression. The BaLasso is adaptive to the
signal level by adopting different shrinkage for different coefficients.
Furthermore, we provide a model selection machinery for the BaLasso by
assessing the posterior conditional mode estimates, motivated by the
hierarchical Bayesian interpretation of the Lasso. Our formulation also permits
prediction using a model averaging strategy. We discuss other variants of this
new approach and provide a unified framework for variable selection using
flexible penalties. Empirical evidence of the attractiveness of the method is
demonstrated via extensive simulation studies and data analysis.