We investigate the effect of static anti-phase stripe order on the weak-field
Hall effect of electrons on a two-dimensional square lattice with electron
dispersion appropriate to the high T$_c$ cuprates. We first consider the cases
where the magnitudes of the spin and charge stripe potentials are smaller than
or of the same order as the bandwidth of the two-dimensional electrons, so that
the electronic properties are not too strongly one-dimensional. In a model with
only spin stripe potential, and at carrier concentrations appropriate to
hole-doped cuprates, increasing the stripe scattering potential from zero leads
to an increase in $R_H$, followed by a sign change. If the scattering amplitude
is yet further increased, a second sign change occurs. The results are in
semiquantitative agreement with data. In a charge-stripe-potential-only model,
$R_H$ increases as the charge stripe scattering strength increases, with no
sign change occurring. In a model with both spin and charge stripe potentials,
$R_H$ may be enhanced or may change sign, depending on the strengths of the two
scattering potentials. We also consider the case in which the magnitudes of the
stripe potentials are much larger than the bandwidth, where analytical results
can be obtained. In this limit, the system is quasi-one-dimensional, while
$R_H$ remains finite and its sign is determined by the carrier density and the
electron band parameters.