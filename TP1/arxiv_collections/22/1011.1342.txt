Filyokov and Karpov [Inzhenerno-Fizicheskii Zhurnal 13, 624 (1967)] have
proposed a theory of non-equilibrium steady states in direct analogy with the
theory of equilibrium states : the principle is to maximize the Shannon entropy
associated to the probability distribution of dynamical trajectories in the
presence of constraints, including the macroscopic current of interest, via the
method of Lagrange multipliers. This maximization leads directly to generalized
Gibbs distribution for the probability distribution of dynamical trajectories,
and to some fluctuation relation of the integrated current. The simplest
stochastic dynamics where these ideas can be applied are discrete-time Markov
chains, defined by transition probabilities $W_{i \to j}$ between
configurations $i$ and $j$ : instead of choosing the dynamical rules $W_{i \to
j} $ a priori, one determines the transition probabilities and the associate
stationary state that maximize the entropy of dynamical trajectories with the
other physical constraints that one wishes to impose. We give a self-contained
and unified presentation of this type of approach, both for discrete-time
Markov Chains and for continuous-time Master Equations. The obtained results
are in full agreement with the Bayesian approach introduced by Evans [Phys.
Rev. Lett. 92, 150601 (2004)] under the name 'Non-equilibrium Counterpart to
detailed balance', and with the 'invariant quantities' derived by Baule and
Evans [Phys. Rev. Lett. 101, 240601 (2008)], but provide a slightly different
perspective via the formulation in terms of an eigenvalue problem.