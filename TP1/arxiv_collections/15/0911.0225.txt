In this paper, we prove a crucial theorem called Mirroring Theorem which
affirms that given a collection of samples with enough information in it such
that it can be classified into classes and subclasses then (i) There exists a
mapping which classifies and subclassifies these samples (ii) There exists a
hierarchical classifier which can be constructed by using Mirroring Neural
Networks (MNNs) in combination with a clustering algorithm that can approximate
this mapping. Thus, the proof of the Mirroring theorem provides a theoretical
basis for the existence and a practical feasibility of constructing
hierarchical classifiers, given the maps. Our proposed Mirroring Theorem can
also be considered as an extension to Kolmogrovs theorem in providing a
realistic solution for unsupervised classification. The techniques we develop,
are general in nature and have led to the construction of learning machines
which are (i) tree like in structure, (ii) modular (iii) with each module
running on a common algorithm (tandem algorithm) and (iv) selfsupervised. We
have actually built the architecture, developed the tandem algorithm of such a
hierarchical classifier and demonstrated it on an example problem.