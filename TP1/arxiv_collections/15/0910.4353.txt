Normalized information distance (NID) uses the theoretical notion of
Kolmogorov complexity, which for practical purposes is approximated by the
length of the compressed version of the file involved, using a real-world
compression program. This practical application is called `normalized
compression distance' and it is trivially computable. It is a parameter-free
similarity measure based on compression, and is used in pattern recognition,
data mining, phylogeny, clustering, and classification. The complexity
properties of its theoretical precursor, the NID, have been open. We show that
the NID is neither upper semicomputable nor lower semicomputable up to any
reasonable precision.