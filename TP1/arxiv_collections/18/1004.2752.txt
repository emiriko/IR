In this paper we study zero-sum two-player stochastic differential games with
jumps with the help of theory of Backward Stochastic Differential Equations
(BSDEs). We generalize the results of Fleming and Souganidis [10] and those by
Biswas [3] by considering a controlled stochastic system driven by a
d-dimensional Brownian motion and a Poisson random measure and by associating
nonlinear cost functionals defined by controlled BSDEs. Moreover, unlike the
both papers cited above we allow the admissible control processes of both
players to depend on all events occurring before the beginning of the game.
This quite natural extension allows the players to take into account such
earlier events, and it makes even easier to derive the dynamic programming
principle. The price to pay is that the cost functionals become random
variables and so also the upper and the lower value functions of the game are a
priori random fields. The use of a new method allows to prove that, in fact,
the upper and the lower value functions are deterministic. On the other hand,
the application of BSDE methods [18] allows to prove a dynamic programming
principle for the upper and the lower value functions in a very
straight-forward way, as well as the fact that they are the unique viscosity
solutions of the upper and the lower integral-partial differential equations of
Hamilton-Jacobi-Bellman-Isaacs' type, respectively. Finally, the existence of
the value of the game is got in this more general setting if Isaacs' condition
holds.