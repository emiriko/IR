As shown by Tropp, 2008, for the concatenation of two orthonormal bases
(ONBs), breaking the square-root bottleneck in compressed sensing does not
require randomization over all the positions of the nonzero entries of the
sparse coefficient vector. Rather the positions corresponding to one of the two
ONBs can be chosen arbitrarily. The two-ONB structure is, however, restrictive
and does not reveal the property that is responsible for allowing to break the
bottleneck with reduced randomness. For general dictionaries we show that if a
sub-dictionary with small enough coherence and large enough cardinality can be
isolated, the bottleneck can be broken under the same probabilistic model on
the sparse coefficient vector as in the two-ONB case.