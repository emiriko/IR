In this paper, we describe centering and noncentering methodology as
complementary techniques for use in parametrization of broad classes of
hierarchical models, with a view to the construction of effective MCMC
algorithms for exploring posterior distributions from these models. We give a
clear qualitative understanding as to when centering and noncentering work
well, and introduce theory concerning the convergence time complexity of Gibbs
samplers using centered and noncentered parametrizations. We give general
recipes for the construction of noncentered parametrizations, including an
auxiliary variable technique called the state-space expansion technique. We
also describe partially noncentered methods, and demonstrate their use in
constructing robust Gibbs sampler algorithms whose convergence properties are
not overly sensitive to the data.