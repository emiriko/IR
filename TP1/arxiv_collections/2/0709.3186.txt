Minimization problems in $\ell^2$ for Tikhonov functionals with sparsity
constraints are considered. Sparsity of the solution is ensured by a weighted
$\ell^1$ penalty term. The necessary and sufficient condition for optimality is
shown to be slantly differentiable (Newton differentiable), hence a semismooth
Newton method is applicable. Local superlinear convergence of this method is
proved. Numerical examples are provided which show that our method compares
favorably with existing approaches.