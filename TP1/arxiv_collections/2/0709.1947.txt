Over the brief time intervals available for processing retinal output,
roughly 50 to 300 msec, the number of extra spikes generated by individual
ganglion cells can be quite variable. Here, computer-generated spike trains
were used to investigate how signal/noise might be improved by utilizing
spatiotemporal correlations among retinal neurons responding to large,
contiguous stimuli. Realistic correlations were produced by modulating the
instantaneous firing probabilities of all stimulated neurons by a common
oscillatory input whose amplitude and temporal structure were consistent with
experimentally measured field potentials and correlograms. Whereas previous
studies have typically measured synergy between pairs of ganglion cells
examined one at a time, or alternatively have employed optimized linear filters
to decode activity across larger populations, the present study investigated a
distributed, non-linear encoding strategy by using Principal Components
Analysis (PCA) to reconstruct simple visual stimuli from up to one million
oscillatory pairwise correlations extracted on single trials from
massively-parallel spike trains as short as 25 msec in duration. By integrating
signals across retinal neighborhoods commensurate in size to classical
antagonistic surrounds, the first principal component of the pairwise
correlation matrix yielded dramatic improvements in signal/noise without
sacrificing fine spatial detail. These results demonstrate how local intensity
information can distributed across hundreds of neurons linked by a common,
stimulus-dependent oscillatory modulation, a strategy that might have evolved
to minimize the number of spikes required to support rapid image
reconstruction.