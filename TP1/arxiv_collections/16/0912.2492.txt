Many successful applications of computer vision to image or video
manipulation are interactive by nature. However, parameters of such systems are
often trained neglecting the user. Traditionally, interactive systems have been
treated in the same manner as their fully automatic counterparts. Their
performance is evaluated by computing the accuracy of their solutions under
some fixed set of user interactions. This paper proposes a new evaluation and
learning method which brings the user in the loop. It is based on the use of an
active robot user - a simulated model of a human user. We show how this
approach can be used to evaluate and learn parameters of state-of-the-art
interactive segmentation systems. We also show how simulated user models can be
integrated into the popular max-margin method for parameter learning and
propose an algorithm to solve the resulting optimisation problem.