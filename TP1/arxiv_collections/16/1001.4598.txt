We consider the problem of revenue-optimal dynamic mechanism design in
settings where agents' types evolve over time as a function of their (both
public and private) experience with items that are auctioned repeatedly over an
infinite horizon. A central question here is understanding what natural
restrictions on the environment permit the design of optimal mechanisms (note
that even in the simpler static setting, optimal mechanisms are characterized
only under certain restrictions). We provide a {\em structural
characterization} of a natural "separable: multi-armed bandit environment
(where the evolution and incentive structure of the a-priori type is decoupled
from the subsequent experience in a precise sense) where dynamic optimal
mechanism design is possible. Here, we present the Virtual Index Mechanism, an
optimal dynamic mechanism, which maximizes the (long term) {\em virtual
surplus} using the classical Gittins algorithm. The mechanism optimally
balances exploration and exploitation, taking incentives into account.