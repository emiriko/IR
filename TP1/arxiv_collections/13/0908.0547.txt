We investigate a method for extracting nonlinear principal components (NPCs).
These NPCs maximize variation subject to smoothness and orthogonality
constraints; but we allow for a general class of constraints and multivariate
probability densities, including densities without compact support and even
densities with algebraic tails. We provide primitive sufficient conditions for
the existence of these NPCs. By exploiting the theory of continuous-time,
reversible Markov diffusion processes, we give a different interpretation of
these NPCs and the smoothness constraints. When the diffusion matrix is used to
enforce smoothness, the NPCs maximize long-run variation relative to the
overall variation subject to orthogonality constraints. Moreover, the NPCs
behave as scalar autoregressions with heteroskedastic innovations; this
supports semiparametric identification and estimation of a multivariate
reversible diffusion process and tests of the overidentifying restrictions
implied by such a process from low frequency data. We also explore implications
for stationary, possibly non-reversible diffusion processes. Finally, we
suggest a sieve method to estimate the NPCs from discretely-sampled data.