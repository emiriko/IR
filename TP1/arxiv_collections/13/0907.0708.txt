Type Ia supernovae result when carbon-oxygen white dwarfs in binary systems
accrete mass from companion stars, reach a critical mass, and explode. The near
uniformity of their light curves makes these supernovae good standard candles
for measuring cosmic expansion, but a correction must be applied to account for
the fact that the brighter supernovae have broader light curves.
One-dimensional modelling, with a certain choice of parameters, can reproduce
this general trend in the width-luminosity relation, but the processes of
ignition and detonation have recently been shown to be intrinsically
asymmetric. Here we report on multi-dimensional modelling of the explosion
physics and radiative transfer that reveals that the breaking of spherical
symmetry is a critical factor in determining both the width luminosity relation
and the observed scatter about it. The deviation from sphericity can also
explain the finite polarization detected in the light from some supernovae. The
slope and normalization of the width-luminosity relation has a weak dependence
on certain properties of the white dwarf progenitor, in particular the trace
abundances of elements other than carbon and oxygen. Failing to correct for
this effect could lead to systematic overestimates of up to 2% in the distance
to remote supernovae.