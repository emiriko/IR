I present a critique of the methods used in a typical paper. This leads to
three broad conclusions about the conventional use of statistical methods.
First, results are often reported in an unnecessarily obscure manner. Second,
the null hypothesis testing paradigm is deeply flawed: estimating the size of
effects and citing confidence intervals or levels is usually better. Third,
there are several issues, independent of the particular statistical concepts
employed, which limit the value of any statistical approach: e.g. difficulties
of generalizing to different contexts, and the weakness of some research in
terms of the size of the effects found. The first two of these are easily
remedied: I illustrate some of the possibilities by re-analyzing the data from
the case study article. The third means that in some contexts a statistical
approach may not be worthwhile. My case study is a management paper, but
similar problems arise in other social sciences. Keywords: Confidence,
Hypothesis testing, Null hypothesis significance tests, Philosophy of
statistics, Statistical methods, User-friendliness.