We analyze the linear stability of a dilute, hot plasma, taking into account
the effects of stratification and anisotropic thermal conduction. The work is
motivated by attempts to understand the dynamics of the intracluster medium in
galaxy clusters. We show that magnetic field configurations that nominally
stabilize either the heat-flux driven buoyancy instability (associated with a
positive thermal gradient) or the magnetothermal instability (negative thermal
gradient) can lead to previously unrecognized g-mode overstabilities. The
driving source of the overstability is either radiative cooling (positive
temperature gradient) or the heat flux itself (negative temperature gradient).
While the implications of these overstabilities have yet to be explored, we
speculate that the cold fronts observed in many relaxed galaxy clusters may be
related to their non-linear evolution.