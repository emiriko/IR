Unambiguous detection of the tidal disruption of a star would allow an
assessment of the presence and masses of supermassive black holes in quiescent
galaxies. It would also provide invaluable information on bulge scale stellar
processes (such as two-body relaxation) via the rate at which stars are
injected into the tidal sphere of influence of the black holes. This rate, in
turn, is essential to predict gravitational radiation emission by compact
object inspirals. The signature of a tidal disruption event is thought to be a
fallback rate for the stellar debris onto the black hole that decreases as
$t^{-5/3}$. This mass flux is often assumed to yield a luminous signal that
decreases in time at the same rate. In this paper, we calculate the
monochromatic lightcurves arising from such an accretion event. Differently
from previous studies, we adopt a more realistic description of the fallback
rate and of the super-Eddigton accretion physics. We also provide simultaneous
lightcurves in optical, UV and X-rays. We show that, after a few months,
optical and UV lightcurves scale as $t^{-5/12}$, and are thus substantially
flatter than the $t^{-5/3}$ behaviour, which is a prerogative of the bolometric
lightcurve, only. At earlier times and for black hole masses $< 10^7 M_{\sun}$,
the wind emission dominates: after reaching a peak of $10^{41}-10^{43}$ erg/s
at roughly a month, the lightcurve decreases steeply as $\sim t^{-2.6}$, until
the disc contribution takes over. The X-ray band, instead, is the best place to
detect the $t^{-5/3}$ "smoking gun" behaviour, although it is displayed only
for roughly a year, before the emission steepens exponentially.