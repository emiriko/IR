Strong astrophysical shocks, diffusively accelerating cosmic rays (CR) ought
to develop CR precursors. The length of such precursor $L_{p}$ is believed to
be set by the ratio of the CR mean free path $\lambda$ to the shock speed,
i.e., $L_{p}\sim c\lambda/V_{sh}\sim cr_{g}/V_{sh}$, which is formally
independent of the CR pressure $P_{c}$. However, the X-ray observations of
supernova remnant shocks suggest that the precursor scale may be significantly
shorter than $L_{p}$ which would question the above estimate unless the
magnetic field is strongly amplified and the gyroradius $r_{g}$ is strongly
reduced over a short (unresolved) spatial scale. We argue that while the CR
pressure builds up ahead of the shock, the acceleration enters into a strongly
nonlinear phase in which an acoustic instability, driven by the CR pressure
gradient, dominates other instabilities (at least in the case of low $\beta$
plasma). In this regime the precursor steepens into a strongly nonlinear front
whose size scales with \emph{the CR pressure}as $L_{f}\sim
L_{p}\cdot(L_{s}/L_{p})^{2}(P_{c}/P_{g})^{2}$, where $L_{s}$ is the scale of
the developed acoustic turbulence, and $P_{c}/P_{g}$ is the ratio of CR to gas
pressure. Since $L_{s}\ll L_{p}$, the precursor scale reduction may be strong
in the case of even a moderate gas heating by the CRs through the acoustic and
(possibly also) the other instabilities driven by the CRs.