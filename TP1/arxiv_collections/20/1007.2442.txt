We propose a new approach for constructing a 3D representation from a 2D
wireframe drawing. A drawing is simply a parallel projection of a 3D object
onto a 2D surface; humans are able to recreate mental 3D models from 2D
representations very easily, yet the process is very difficult to emulate
computationally. We hypothesize that our ability to perform this construction
relies on the angles in the 2D scene, among other geometric properties. Being
able to reproduce this reconstruction process automatically would allow for
efficient and robust 3D sketch interfaces. Our research focuses on the
relationship between 2D geometry observable in the sketch and 3D geometry
derived from a potential 3D construction. We present a fully automated system
that constructs 3D representations from 2D wireframes using a neural network in
conjunction with a genetic search algorithm.