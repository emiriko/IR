RANSAC is a popular technique for estimating model parameters in the presence
of outliers. The best speed is achieved when the minimum possible number of
points is used to estimate hypotheses for the model. Many useful problems can
be represented using polynomial constraints (for instance, the determinant of a
fundamental matrix must be zero) and so have a number of solutions which are
consistent with a minimal set. A considerable amount of effort has been
expended on finding the constraints of such problems, and these often require
the solution of systems of polynomial equations. We show that better
performance can be achieved by using a simple optimization based approach on
minimal sets. For a given minimal set, the optimization approach is not
guaranteed to converge to the correct solution. However, when used within
RANSAC the greater speed and numerical stability results in better performance
overall, and much simpler algorithms. We also show that by selecting more than
the minimal number of points and using robust optimization can yield better
results for very noisy by reducing the number of trials required. The increased
speed of our method demonstrated with experiments on essential matrix
estimation.