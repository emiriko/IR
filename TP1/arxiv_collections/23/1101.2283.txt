Nonequilibrium states induced by an applied bias voltage (V) and the
corresponding current-voltage characteristics of one-dimensional models
describing band and Mott insulators are investigated theoretically by using
nonequilibrium Green's functions. We attach the models to metallic electrodes
whose effects are incorporated into the self-energy. Modulation of the electron
density and the scalar potential coming from the additional long-range
interaction are calculated self-consistently within the Hartree approximation.
For both models of band and Mott insulators with length L_C, the bias voltage
induces a breakdown of the insulating state, whose threshold shows a crossover
depending on L_C. It is determined basically by the bias $V_{th}\sim \Delta$
for L_C smaller than the correlation length $\xi=W/\Delta$ where W denotes the
bandwidth and $\Delta$ the energy gap. For systems with $L_C\gg \xi$, the
threshold is governed by the electric field, $V_{th}/L_C$, which is consistent
with a Landau-Zener-type breakdown, $V_{th}/L_C\propto \Delta^2/W$. We
demonstrate that the spatial dependence of the scalar potential is crucially
important for this crossover by showing the case without the scalar potential,
where the breakdown occurs at $V_{th}\sim \Delta$ regardless of the length L_C.