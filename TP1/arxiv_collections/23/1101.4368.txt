An important aspect of Bayesian model selection is how to deal with huge
model spaces, since exhaustive enumeration of all the models entertained is
unfeasible and inferences have to be based on the very small proportion of
models visited. This is the case for the variable selection problem, with a
moderate to large number of possible explanatory variables being considered in
this paper. We review some of the strategies proposed in the literature and
argue that inferences based on empirical frequencies via Markov Chain Monte
Carlo sampling of the posterior distribution outperforms recently proposed
searching methods. We give a plausible yet very simple explanation of this
effect, showing that estimators based on frequencies are unbiased. The results
obtained in two illustrative examples provide strong evidence in favor of our
arguments.