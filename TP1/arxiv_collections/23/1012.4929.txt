Delayed detonations of Chandrasekhar-mass white dwarfs (WDs) have been very
successful in explaining the spectra, light curves, and the width-luminosity
relation of spectroscopically normal Type Ia supernovae (SNe Ia). The ignition
of the thermonuclear deflagration flame at the end of the convective carbon
"simmering" phase in the core of the WD is still not well understood and much
about the ignition kernel distribution remains unknown. Furthermore, the
central density at the time of ignition depends on the still uncertain screened
carbon fusion reaction rates, the accretion history and cooling time of the
progenitor, and the composition. We present the results of twelve
high-resolution three-dimensional delayed detonation SN Ia explosion
simulations that employ a new criterion to trigger the deflagration to
detonation transition (DDT). All simulations trigger our DDT criterion and the
resulting delayed detonations unbind the star. We find a trend of increasing
iron group element (IGE) production with increasing central density for bright,
faint, and intermediate SNe. The total 56Ni yield, however, remains more or
less constant, even though increased electron captures at high density result
in a decreasing 56Ni mass fraction of the IGE material. We attribute this to an
approximate balance of 56Ni producing and destroying effects. The deflagrations
that were ignited at higher density initially have a faster growth rate of
subgrid-scale turbulence. Hence, the effective flame speed increases faster,
which triggers the DDT criterion earlier, at a time when the central density of
the expanded star is higher. This leads to an overall increase of IGE
production, which off-sets the percental reduction of 56Ni due to
neutronization.