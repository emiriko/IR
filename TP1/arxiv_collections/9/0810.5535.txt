A new combinatorial-probabilistic diagnostic entropy has been introduced. It
describes the pair-wise sum of probabilities of system conditions that have to
be distinguished during the diagnosing process. The proposed measure describes
the uncertainty of the system conditions, and at the same time complexity of
the diagnosis problem. Treating the assumed combinatorial-diagnostic entropy as
a primary notion, the information delivered by the symptoms has been defined.
The relationships have been derived to facilitate explicit, quantitative
assessment of the information of a single symptom as well as that of a symptoms
set. It has been proved that the combinatorial-probabilistic information shows
the property of additivity. The presented measures are focused on diagnosis
problem, but they can be easily applied to other disciplines such as decision
theory and classification.