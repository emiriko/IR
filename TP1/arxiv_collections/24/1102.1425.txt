We use infrared spectroscopy and photometry to empirically define the
intrinsic, thermal infrared spectral energy distribution (i.e., 6-100 um SED)
of typical active galactic nuclei (i.e., 2-10 keV luminosity,
Lx=10^{42}-10^{44} ergs/s AGNs). On average, the infrared SED of typical AGNs
is best described as a broken power-law at <40 um that falls steeply at >40um
(i.e., at far-infrared wavelengths). Despite this fall-off at long wavelengths,
at least 3 of the 11 AGNs in our sample have observed SEDs that are
AGN-dominated even at 60 um, demonstrating the importance of accounting for
possible AGN contribution even at far-infrared wavelengths. Our results also
suggest that the average intrinsic AGN 6-100 um SED gets bluer with increasing
X-ray luminosity, a trend seen both within our sample and also when we compare
against the intrinsic SEDs of more luminous quasars (i.e., Lx>10^{44} ergs/s).
We compare our intrinsic AGN SEDs with predictions from dusty torus models and
find they are more closely matched by clumpy, rather than continuous, torus
models. Next, we use our intrinsic AGN SEDs to define a set of correction
factors to convert either monochromatic infrared or X-ray luminosities into
total intrinsic AGN infrared (i.e., 8-1000 um) luminosities. Finally, we
outline a procedure that uses our newly defined intrinsic AGN infrared SEDs, in
conjunction with a selection of host-galaxy templates, to fit the infrared
photometry of composite galaxies and measure the AGN contribution to their
total infrared output. We verify the accuracy of our SED fitting procedure by
comparing our results to two independent measures of AGN contribution. Our SED
fitting procedure opens up the possibility of measuring the intrinsic AGN
luminosities of large numbers of galaxies with well-sampled infrared data
(e.g., IRAS, ISO, Spitzer and Herschel).