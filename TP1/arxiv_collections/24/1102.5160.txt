We present non-LTE time-dependent radiative-transfer simulations of supernova
(SN) IIb/Ib/Ic spectra and light curves, based on ~1B-energy piston-driven
ejecta, with and without 56Ni, produced from single and binary Wolf-Rayet (W-R)
stars evolved at solar and sub-solar metallicities. Our bolometric light curves
show a 10-day long post-breakout plateau with a luminosity of 1-5x10^7Lsun. In
our 56Ni-rich models, with ~3Msun ejecta masses, this plateau precedes a
20-30-day long re-brightening phase initiated by the outward-diffusing heat
wave powered by radioactive decay at depth. In low ejecta-mass models with
moderate mixing, Gamma-ray leakage starts as early as ~50d after explosion and
causes the nebular luminosity to steeply decline by ~0.02mag/d. Such
signatures, which are observed in standard SNe IIb/Ib/Ic, are consistent with
low-mass progenitors derived from a binary-star population. We propose that the
majority of stars with an initial mass ~<20Msun yield SNe II-P if 'effectively"
single, SNe IIb/Ib/Ic if part of a close binary system, and SN-less black holes
if more massive. Our ejecta, with outer hydrogen mass fractions as low as
~>0.01 and a total hydrogen mass of ~>0.001Msun, yield the characteristic SN
IIb spectral morphology at early times. However, by ~15d after the explosion,
only Halpha may remain as a weak absorption feature. Our binary models,
characterised by helium surface mass fractions of ~>0.85, systematically show
HeI lines during the post-breakout plateau, irrespective of the 56Ni abundance.
Synthetic spectra show a strong sensitivity to metallicity, which offers the
possibility to constrain it directly from SN spectroscopic modelling.