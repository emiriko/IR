We study the problem of multiple hypothesis testing (HT) in view of a
rejection option. That model of HT has many different applications. Errors in
testing of M hypotheses regarding the source distribution with an option of
rejecting all those hypotheses are considered. The source is discrete and
arbitrarily varying (AVS). The tradeoffs among error probability
exponents/reliabilities associated with false acceptance of rejection decision
and false rejection of true distribution are investigated and the optimal
decision strategies are outlined. The main result is specialized for discrete
memoryless sources (DMS) and studied further. An interesting insight that the
analysis implies is the phenomenon (comprehensible in terms of
supervised/unsupervised learning) that in optimal discrimination within M
hypothetical distributions one permits always lower error than in deciding to
decline the set of hypotheses. Geometric interpretations of the optimal
decision schemes are given for the current and known bounds in multi-HT for
AVS's.