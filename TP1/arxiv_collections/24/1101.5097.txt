Learning latent structure in complex networks has become an important problem
fueled by many types of networked data originating from practically all fields
of science. In this paper, we propose a new non-parametric Bayesian
multiple-membership latent feature model for networks. Contrary to existing
multiple-membership models that scale quadratically in the number of vertices
the proposed model scales linearly in the number of links admitting
multiple-membership analysis in large scale networks. We demonstrate a
connection between the single membership relational model and multiple
membership models and show on "real" size benchmark network data that
accounting for multiple memberships improves the learning of latent structure
as measured by link prediction while explicitly accounting for multiple
membership result in a more compact representation of the latent structure of
networks.