The notion of divergence information of an ensemble of probability
distributions was introduced by Jain, Radhakrishnan, and Sen in the context of
the ``substate theorem''. Since then, divergence has been recognized as a more
natural measure of information in several situations in quantum and classical
communication. We construct ensembles of probability distributions for which
divergence information may be significantly smaller than the more standard
Holevo information. As a result, we establish that lower bounds previously
shown for Holevo information are weaker than similar ones shown for divergence
information.