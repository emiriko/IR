Many of the traditional results in information theory, such as the channel
coding theorem or the source coding theorem, are restricted to scenarios where
the underlying resources are independent and identically distributed (i.i.d.)
over a large number of uses. To overcome this limitation, two different
techniques, the information spectrum method and the smooth entropy framework,
have been developed independently. They are based on new entropy measures,
called spectral entropy rates and smooth entropies, respectively, that
generalize Shannon entropy (in the classical case) and von Neumann entropy (in
the more general quantum case). Here, we show that the two techniques are
closely related. More precisely, the spectral entropy rate can be seen as the
asymptotic limit of the smooth entropy. Our results apply to the quantum
setting and thus include the classical setting as a special case.