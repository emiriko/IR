A restless multi-armed bandit problem that arises in multichannel
opportunistic communications is considered, where channels are modeled as
independent and identical Gilbert-Elliot channels and channel state
observations are subject to errors. A simple structure of the myopic policy is
established under a certain condition on the false alarm probability of the
channel state detector. It is shown that the myopic policy has a semi-universal
structure that reduces channel selection to a simple round-robin procedure and
obviates the need to know the underlying Markov transition probabilities. The
optimality of the myopic policy is proved for the case of two channels and
conjectured for the general case based on numerical examples.