Estimation of molecular evolutionary divergence times requires models of rate
change. These vary with regard to the assumption of what quantity is penalized.
The possibilities considered are the rate of evolution, the log of the rate of
evolution and the inverse of the rate of evolution. These models also vary with
regard to how time affects the expected variance of rate change. Here the
alternatives are not at all, linearly with time and as the product of rate and
time. This results in a set of nine models, both random walks and Brownian
motion. A priori any of these models could be correct, yet different
researchers may well prefer, or simply use, one rather than the others. Another
variable is whether to use a scaling factor to take account of the variance of
the process of rate change being unknown and therefore avoid minimizing the
penalty function with unrealistically large times. Here the difference these
models and assumptions make on a tree of mammals, with the root fixed and with
a single internal node fixed, is measured. The similarity of models is measured
as the correlation of their time estimates and visualized with a least squares
tree. The fit of model to data is measured and Q-Q plots are shown. Comparing
model estimates with each other, the age of clades within Laurasiatheria are
seen to vary far more across models than those within Supraprimates (informally
called Euarchontoglires). Especially problematic are the often-used fossil
calibrated nodes of horse/rhino and whale/hippo clashing with times within
Supraprimates and in particular no fossil rodent teeth older than ~60 mybp. A
scaling factor in addition to penalizing rate change is seen to yield
consistent relative time estimates irrespective of exactly where the
calibration point is placed.