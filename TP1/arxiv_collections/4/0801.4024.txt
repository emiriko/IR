It is not obvious what fraction of all the potential information residing in
the molecules and structures of living systems is significant or meaningful to
the system. Sets of random sequences or identically repeated sequences, for
example, would be expected to contribute little or no useful information to a
cell. This issue of quantitation of information is important since the ebb and
flow of biologically significant information is essential to our quantitative
understanding of biological function and evolution. Motivated specifically by
these problems of biological information, we propose here a class of measures
to quantify the contextual nature of the information in sets of objects, based
on Kolmogorov's intrinsic complexity. Such measures discount both random and
redundant information and are inherent in that they do not require a defined
state space to quantify the information. The maximization of this new measure,
which can be formulated in terms of the universal information distance, appears
to have several useful and interesting properties, some of which we illustrate
with examples.