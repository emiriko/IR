We consider the problem of predicting as well as the best linear combination
of d given functions in least squares regression, and variants of this problem
including constraints on the parameters of the linear combination. When the
input distribution is known, there already exists an algorithm having an
expected excess risk of order d/n, where n is the size of the training data.
Without this strong assumption, standard results often contain a multiplicative
log n factor, and require some additional assumptions like uniform boundedness
of the d-dimensional input representation and exponential moments of the
output. This work provides new risk bounds for the ridge estimator and the
ordinary least squares estimator, and their variants. It also provides
shrinkage procedures with convergence rate d/n (i.e., without the logarithmic
factor) in expectation and in deviations, under various assumptions. The key
common surprising factor of these results is the absence of exponential moment
condition on the output distribution while achieving exponential deviations.
All risk bounds are obtained through a PAC-Bayesian analysis on truncated
differences of losses. Finally, we show that some of these results are not
particular to the least squares loss, but can be generalized to similar
strongly convex loss functions.