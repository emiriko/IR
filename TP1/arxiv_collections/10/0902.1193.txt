This article is a response to an off-the-record discussion that I had at an
international meeting of epidemiologists. It centered on a concern, perhaps
widely spread, that measurement error adjustment methods can induce positive
bias in results of epidemiological studies when there is no true association. I
trace the possible history of this supposition and test it in a simulation
study of both continuous and binary health outcomes under a classical
multiplicative measurement error model. A Bayesian measurement adjustment
method is used. The main conclusion is that adjustment for the presumed
measurement error does not 'induce' positive associations, especially if the
focus of the interpretation of the result is taken away from the point
estimate. This is in line with properties of earlier measurement error
adjustment methods introduced to epidemiologists in the 1990s. An heuristic
argument is provided to support the generalizability of this observation in the
Bayesian framework. I find that when there is no true association, positive
bias can only be induced by indefensible manipulation of the priors, such that
they dominate the data. The misconception about bias induced by measurement
error adjustment should be more clearly explained during the training of
epidemiologists to ensure the appropriate (and wider) use of measurement error
correction procedures. The simple message that can be derived from this paper
is: 'Do not focus on point estimates, but mind the gap between boundaries that
reflect variability in the estimate'. And of course: 'Treat measurement error
as a tractable problem that deserves much more attention than just a
qualitative (throw-away) discussion'.