Neuronal activity arises from an interaction between ongoing firing generated
spontaneously by neural circuits and responses driven by external stimuli.
Using mean-field analysis, we ask how a neural network that intrinsically
generates chaotic patterns of activity can remain sensitive to extrinsic input.
We find that inputs not only drive network responses, they also actively
suppress ongoing activity, ultimately leading to a phase transition in which
chaos is completely eliminated. The critical input intensity at the phase
transition is a non-monotonic function of stimulus frequency, revealing a
"resonant" frequency at which the input is most effective at suppressing chaos
even though the power spectrum of the spontaneous activity peaks at zero and
falls exponentially. A prediction of our analysis is that the variance of
neural responses should be most strongly suppressed at frequencies matching the
range over which many sensory systems operate.