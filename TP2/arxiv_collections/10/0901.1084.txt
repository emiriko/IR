The nonlinear filter for an ergodic signal observed in white noise is said to
achieve maximal accuracy if the stationary filtering error vanishes as the
signal to noise ratio diverges. We give a general characterization of the
maximal accuracy property in terms of various systems theoretic notions. When
the signal state space is a finite set explicit necessary and sufficient
conditions are obtained, while the linear Gaussian case reduces to a classic
result of Kwakernaak and Sivan (1972).