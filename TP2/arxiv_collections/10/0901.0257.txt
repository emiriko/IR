One of the most intriguing features discovered by Swift is a plateau phase in
the X-ray flux decay of about 70% of the afterglows of gamma-ray bursts (GRBs).
The physical origin of this feature is still being debated. We constrain the
proposed interpretations, based on the intrinsic temporal properties of the
plateau phase. We selected and analyzed all the Swift/XRT GRB afterglows at
known redshift observed between March 2005 and June 2008 featuring a shallow
decay phase in their X-ray lightcurves. For our sample of 21 GRBs we find an
anticorrelation of the logarithm of the duration of the shallow phase with re
dshift, with a Spearman rank-order correlation coefficient of r=-0.4 and a null
hypothesis probability of 5%. When we correct the durations for cosmological
dilation, the anticorrelation strenghtens, with r=-0.6 and a null hypothesis
probability of 0.4%. Considering only those GRBs in our sample that have a
well-measured burst peak energy (8 out of 21), we find an anticorrelation
between the energy of the burst and the shallow phase duration, with r=-0.80
and a null hypothesis probability of 1.8%. If the burst energy anticorrelation
with the shallow phase duration is real, then the dependence of the shallow
phase on redshift could be the result of a selection effect, since on average
high-redshift bursts with lower energies and longer plateaus would be missed. A
burst energy anticorrelation with the shallow phase duration would be expected
if the end of the plateau arises from a collimated outflow. Alternative
scenarios are briefly discussed involving a possible cosmological evolution of
the mechanism responsible for the X-ray shallow decay.