We study the square-lattice XY model in the presence of random phase shifts.
We consider two different disorder distributions with zero average shift and
investigate the low-temperature quasi-long-range order phase which occurs for
sufficiently low disorder. By means of Monte Carlo simulations we determine
several universal quantities which are then compared with the analytic
predictions of the random spin-wave theory. We observe a very good agreement
which indicates that the universal long-distance behavior in the whole
low-disorder low-temperature phase is fully described by the random spin-wave
theory.