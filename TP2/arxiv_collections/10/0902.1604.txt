As the World Wide Web is growing rapidly, it is getting increasingly
challenging to gather representative information about it. Instead of crawling
the web exhaustively one has to resort to other techniques like sampling to
determine the properties of the web. A uniform random sample of the web would
be useful to determine the percentage of web pages in a specific language, on a
topic or in a top level domain. Unfortunately, no approach has been shown to
sample the web pages in an unbiased way. Three promising web sampling
algorithms are based on random walks. They each have been evaluated
individually, but making a comparison on different data sets is not possible.
We directly compare these algorithms in this paper. We performed three random
walks on the web under the same conditions and analyzed their outcomes in
detail. We discuss the strengths and the weaknesses of each algorithm and
propose improvements based on experimental results.