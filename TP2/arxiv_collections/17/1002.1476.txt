We measure the angular auto-correlation functions (w) of SDSS galaxies
selected to have photometric redshifts 0.1 < z < 0.4 and absolute r-band
magnitudes Mr < -21.2. We split these galaxies into five overlapping redshift
shells of width 0.1 and measure w in each subsample in order to investigate the
evolution of SDSS galaxies. We find that the bias increases substantially with
redshift - much more so than one would expect for a passively evolving sample.
We use halo-model analysis to determine the best-fit
halo-occupation-distribution (HOD) for each subsample, and the best-fit models
allow us to interpret the change in bias physically. In order to properly
interpret our best-fit HODs, we convert each halo mass to its z = 0 passively
evolved bias (bo), enabling a direct comparison of the best-fit HODs at
different redshifts. We find that the minimum halo bo required to host a galaxy
decreases as the redshift decreases, suggesting that galaxies with Mr < -21.2
are forming in halos at the low-mass end of the HODs over our redshift range.
We use the best-fit HODs to determine the change in occupation number divided
by the change in mass of halos with constant bo and we find a sharp peak at bo
~ 0.9 - corresponding to an average halo mass of ~ 10^12Msol/h. We thus present
the following scenario: the bias of galaxies with Mr < -21.2 decreases as the
Universe evolves because these galaxies form in halos of mass ~ 10^12Msol/h
(independent of redshift), and the bias of these halos naturally decreases as
the Universe evolves.