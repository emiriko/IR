For high throughput applications, turbo-like iterative decoders are
implemented with parallel architectures. However, to be efficient parallel
architectures require to avoid collision accesses i.e. concurrent read/write
accesses should not target the same memory block. This consideration applies to
the two main classes of turbo-like codes which are Low Density Parity Check
(LDPC) and Turbo-Codes. In this paper we propose a methodology which finds a
collision-free mapping of the variables in the memory banks and which optimizes
the resulting interleaving architecture. Finally, we show through a pedagogical
example the interest of our approach compared to state-of-the-art techniques.