Motivated by a considerable scatter in the observationally inferred lifetimes
of the embedded phase of star formation, we study the duration of the Class 0
and Class I phases in upper-mass brown dwarfs and low-mass stars using
numerical hydrodynamics simulations of the gravitational collapse of a large
sample of cloud cores. We resolve the formation of a star/disk/envelope system
and extend our numerical simulations to the late accretion phase when the
envelope is nearly totally depleted of matter. We adopted a classification
scheme of Andre et al. and calculate the lifetimes of the Class 0 and Class I
phases (\tau_C0 and \tau_CI, respectively) based on the mass remaining in the
envelope. When cloud cores with various rotation rates, masses, and sizes (but
identical otherwise) are considered, our modeling reveals a sub-linear
correlation between the Class 0 lifetimes and stellar masses in the Class 0
phase with the least-squares fit exponent m=0.8 \pm 0.05. The corresponding
correlation between the Class I lifetimes and stellar masses in the Class I is
super-linear with m=1.2 \pm 0.05. If a wider sample of cloud cores is
considered, which includes possible variations in the initial gas temperature,
cloud core truncation radii, density enhancement amplitudes, initial gas
density and angular velocity profiles, and magnetic fields, then the
corresponding exponents may decrease by as much as 0.3. The duration of the
Class I phase is found to be longer than that of the Class~0 phase in most
models, with a mean ratio \tau_CI / \tau_C0 \approx 1.5--2. A notable exception
are YSOs that form from cloud cores with large initial density enhancements, in
which case \tau_C0 may be greater than \tau_CI. Moreover, the upper-mass (>=
1.0 Msun) cloud cores with frozen-in magnetic fields and high cloud core
rotation rates may have the \tau_CI / \tau_C0 ratios as large as 3.0--4.0.
(Abdridged).