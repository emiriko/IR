The inclusion of a macroscopic adaptive threshold is studied for the
retrieval dynamics of both layered feedforward and fully connected neural
network models with synaptic noise. These two types of architectures require a
different method to be solved numerically. In both cases it is shown that, if
the threshold is chosen appropriately as a function of the cross-talk noise and
of the activity of the stored patterns, adapting itself automatically in the
course of the recall process, an autonomous functioning of the network is
guaranteed. This self-control mechanism considerably improves the quality of
retrieval, in particular the storage capacity, the basins of attraction and the
mutual information content.