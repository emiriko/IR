In our former work [K. Tadaki, Local Proceedings of CiE 2008, pp.425-434,
2008], we developed a statistical mechanical interpretation of algorithmic
information theory by introducing the notion of thermodynamic quantities at
temperature T, such as free energy F(T), energy E(T), and statistical
mechanical entropy S(T), into the theory. These quantities are real functions
of real argument T>0. We then discovered that, in the interpretation, the
temperature T equals to the partial randomness of the values of all these
thermodynamic quantities, where the notion of partial randomness is a stronger
representation of the compression rate by program-size complexity. Furthermore,
we showed that this situation holds for the temperature itself as a
thermodynamic quantity. Namely, the computability of the value of partition
function Z(T) gives a sufficient condition for T in (0,1) to be a fixed point
on partial randomness. In this paper, we show that the computability of each of
all the thermodynamic quantities above gives the sufficient condition also.
Moreover, we show that the computability of F(T) gives completely different
fixed points from the computability of Z(T).