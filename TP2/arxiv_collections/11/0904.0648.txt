We show that Boolean functions expressible as monotone disjunctive normal
forms are PAC-evolvable under a uniform distribution on the Boolean cube if the
hypothesis size is allowed to remain fixed. We further show that this result is
insufficient to prove the PAC-learnability of monotone Boolean functions,
thereby demonstrating a counter-example to a recent claim to the contrary. We
further discuss scenarios wherein evolvability and learnability will coincide
as well as scenarios under which they differ. The implications of the latter
case on the prospects of learning in complex hypothesis spaces is briefly
examined.