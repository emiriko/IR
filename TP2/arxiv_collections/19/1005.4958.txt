A sample consisting of 27 X-ray selected galaxy clusters from the XMM-LSS
survey is used to study the evolution in the X-ray surface brightness profiles
of the hot intracluster plasma. These systems are mostly groups and poor
clusters, with temperatures 0.6-4.8 keV, spanning the redshift range 0.05 to
1.05. Comparing the profiles with a standard beta-model motivated by studies of
low redshift groups, we find 54% of our systems to possess a central excess,
which we identify with a cuspy cool core. Fitting beta-model profiles, allowing
for blurring by the XMM point spread function, we investigate trends with both
temperature and redshift in the outer slope (beta) of the X-ray surface
brightness, and in the incidence of cuspy cores. Fits to individual cluster
profiles and to profiles stacked in bands of redshift and temperature indicate
that the incidence of cuspy cores does not decline at high redshifts, as has
been reported in rich clusters. Rather such cores become more prominent with
increasing redshift. Beta shows a positive correlation with both redshift and
temperature. Given the beta-T trend seen in local systems, we assume that
temperature is the primary driver for this trend. Our results then demonstrate
that this correlation is still present at z~0.3, where most of our clusters
reside.