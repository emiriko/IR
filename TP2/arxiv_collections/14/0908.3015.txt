Quantum simulation is a highly ambitious program in cold atom research
currently being pursued in laboratories worldwide. The goal is to use cold
atoms in optical lattice to simulate models for unsolved strongly correlated
systems, so as to deduce their properties directly from experimental data. An
important step in this effort is to determine the temperature of the system,
which is essential for deducing all thermodynamic functions. This step,
however, remains difficult for lattice systems at the moment. Here, we propose
a method based on a generalized fluctuation-dissipation theorem. It does not
reply on numerical simulations and is a universal thermometry for all quantum
gases systems including mixtures and spinor gases. It is also unaffected by
photon shot noise.