We conducted an extensive computational experiment, lasting multiple
CPU-years, to optimally select parameters for two important classes of
algorithms for finding sparse solutions of underdetermined systems of linear
equations. We make the optimally tuned implementations available at {\tt
sparselab.stanford.edu}; they run `out of the box' with no user tuning: it is
not necessary to select thresholds or know the likely degree of sparsity. Our
class of algorithms includes iterative hard and soft thresholding with or
without relaxation, as well as CoSaMP, subspace pursuit and some natural
extensions. As a result, our optimally tuned algorithms dominate such
proposals. Our notion of optimality is defined in terms of phase transitions,
i.e. we maximize the number of nonzeros at which the algorithm can successfully
operate. We show that the phase transition is a well-defined quantity with our
suite of random underdetermined linear systems. Our tuning gives the highest
transition possible within each class of algorithms.