This work concerns testing the number of parameters in one hidden layer
multilayer perceptron (MLP). For this purpose we assume that we have
identifiable models, up to a finite group of transformations on the weights,
this is for example the case when the number of hidden units is know. In this
framework, we show that we get a simple asymptotic distribution, if we use the
logarithm of the determinant of the empirical error covariance matrix as cost
function.