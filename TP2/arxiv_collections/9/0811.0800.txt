We study the feasibility and noise sensitivity of portfolio optimization
under some downside risk measures (Value-at-Risk, Expected Shortfall, and
semivariance) when they are estimated by fitting a parametric distribution on a
finite sample of asset returns. We find that the existence of the optimum is a
probabilistic issue, depending on the particular random sample, in all three
cases. At a critical combination of the parameters of these problems we find an
algorithmic phase transition, separating the phase where the optimization is
feasible from the one where it is not. This transition is similar to the one
discovered earlier for Expected Shortfall based on historical time series. We
employ the replica method to compute the phase diagram, as well as to obtain
the critical exponent of the estimation error that diverges at the critical
point. The analytical results are corroborated by Monte Carlo simulations.