We propose a generalized entropy maximization procedure, which takes into
account the generalized averaging procedures and information gain definitions
underlying the generalized entropies. This novel generalized procedure is then
applied to Renyi and Tsallis entropies. The generalized entropy maximization
procedure for Renyi entropies results in the exponential stationary
distribution asymptotically for q is between [0,1] in contrast to the
stationary distribution of the inverse power law obtained through the ordinary
entropy maximization procedure. Another result of the generalized entropy
maximization procedure is that one can naturally obtain all the possible
stationary distributions associated with the Tsallis entropies by employing
either ordinary or q-generalized Fourier transforms in the averaging procedure.