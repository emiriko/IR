We study the optimality conditions of information transfer in systems with
memory in the low signal-to-noise ratio regime of vanishing input amplitude. We
find that the optimal mutual information is represented by a maximum-variance
of the signal time course, with correlation structure determined by the Fisher
information matrix. We provide illustration of the method on a simple
biologically-inspired model of electro-sensory neuron. Our general results
apply also to the study of information transfer in single neurons subject to
weak stimulation, with implications to the problem of coding efficiency in
biological systems.