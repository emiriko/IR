The reliability of infrared (IR) and ultraviolet (UV) emissions to measure
star formation rates in galaxies is investigated for a large sample of galaxies
observed with the SPIRE and PACS instruments on Herschel as part of the HerMES
project. We build flux-limited 250 micron samples of sources at redshift z<1,
cross-matched with the Spitzer/MIPS and GALEX catalogues. About 60 % of the
Herschel sources are detected in UV. The total IR luminosities, L_IR, of the
sources are estimated using a SED-fitting code that fits to fluxes between 24
and 500 micron. Dust attenuation is discussed on the basis of commonly-used
diagnostics: the L_IR/L_UV ratio and the slope, beta, of the UV continuum. A
mean dust attenuation A_UV of ~ 3 mag is measured in the samples. L_IR/L_UV is
found to correlate with L_IR. Galaxies with L_IR > 10 ^{11} L_sun and 0.5< z<1
exhibit a mean dust attenuation A_UV about 0.7 mag lower than that found for
their local counterparts, although with a large dispersion. Our galaxy samples
span a large range of beta and L_IR/L_UV values which, for the most part, are
distributed between the ranges defined by the relations found locally for
starburst and normal star-forming galaxies. As a consequence the recipe
commonly applied to local starbursts is found to overestimate the dust
attenuation correction in our galaxy sample by a factor ~2-3 .