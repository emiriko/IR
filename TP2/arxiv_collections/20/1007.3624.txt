We prove the following facts about the language recognition power of quantum
Turing machines (QTMs) in the unbounded error setting: QTMs are strictly more
powerful than probabilistic Turing machines for any common space bound $ s $
satisfying $ s(n)=o(\log \log n) $. For "one-way" Turing machines, where the
input tape head is not allowed to move left, the above result holds for
$s(n)=o(\log n) $. We also give a characterization for the class of languages
recognized with unbounded error by real-time quantum finite automata (QFAs)
with restricted measurements. It turns out that these automata are equal in
power to their probabilistic counterparts, and this fact does not change when
the QFA model is augmented to allow general measurements and mixed states.
Unlike the case with classical finite automata, when the QFA tape head is
allowed to remain stationary in some steps, more languages become recognizable.
We define and use a QTM model that generalizes the other variants introduced
earlier in the study of quantum space complexity.