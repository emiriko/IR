We analyze infrared divergences arising in calculations involving light and
massless fields in de Sitter space. We show that these arise from an incorrect
treatment of the constant mode of the field, and show that a correct
quantization leads to a well-defined and calculable perturbation expansion. We
illustrate this by computing the first nontrivial loop correction in a theory
of a massless scalar field with a quartic interaction.