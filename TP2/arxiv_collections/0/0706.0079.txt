It is shown that inhomogeneous nonlinear interactions in a Bose-Einstein
condensate loaded in an optical lattice can result in delocalizing transition
in one dimension, what sharply contrasts to the known behavior of discrete and
periodic systems with homogeneous nonlinearity. The transition can be
originated either by decreasing the amplitude of the linear periodic potential
or by the change of the mean value of the periodic nonlinearity. The dynamics
of the delocalizing transition is studied.