Evolutionary game theory has been an important tool for describing economic
and social behaviour for decades. Approximate mean value equations describing
the time evolution of strategy concentrations can be derived from the players'
microscopic update rules. We show that they can be generalized to a learning
process. As an example, we compare a restricted imitation process, in which
unused parts of the role model's meta-strategy are hidden from the imitator,
with the widely used imitation rule that allows the imitator to adopt the
entire meta-strategy of the role model. This change in imitation behaviour
greatly affects dynamics and stationary states in the iterated prisoner
dilemma. Particularly we find Grim Trigger to be a more successful strategy
than Tit-For-Tat especially in the weak selection regime.