At present, there is considerable interest in using atomic fermions in
optical lattices to emulate the mathematical models that have been used to
study strongly correlated electronic systems. Some of these models, such as the
two dimensional fermion Hubbard model, are notoriously difficult to solve, and
their key properties remain controversial despite decades of studies. It is
hoped that the emulation experiments will shed light on some of these long
standing problems. A successful emulation, however, requires reaching
temperatures as low as $10^{-12}$K and beyond, with entropy per particle far
lower than what can be achieved today. Achieving such low entropy states is an
essential step and a grand challenge of the whole emulation enterprise. In this
paper, we point out a method to literally squeeze the entropy out from a Fermi
gas into a surrounding Bose-Einstein condensed gas (BEC), which acts as a heat
reservoir. This method allows one to reduce the entropy per particle of a
lattice Fermi gas to a few percent of the lowest value obtainable today.