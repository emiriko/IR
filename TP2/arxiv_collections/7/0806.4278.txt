We develop the dynamic programming approach for a family of infinite horizon
boundary control problems with linear state equation and convex cost. We prove
that the value function of the problem is the unique regular solution of the
associated stationary Hamilton--Jacobi--Bellman equation and use this to prove
existence and uniqueness of feedback controls. The idea of studying this kind
of problem comes from economic applications, in particular from models of
optimal investment with vintage capital. Such family of problems has already
been studied in the finite horizon case by Faggian. The infinite horizon case
is more difficult to treat and it is more interesting from the point of view of
economic applications, where what mainly matters is the behavior of optimal
trajectories and controls in the long run. The study of infinite horizon is
here performed through a nontrivial limiting procedure from the corresponding
finite horizon problem.