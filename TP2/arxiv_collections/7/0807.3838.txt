The performance (accuracy and robustness) of several clustering algorithms is
studied for linearly dependent random variables in the presence of noise. It
turns out that the error percentage quickly increases when the number of
observations is less than the number of variables. This situation is common
situation in experiments with DNA microarrays. Moreover, an {\it a posteriori}
criterion to choose between two discordant clustering algorithm is presented.