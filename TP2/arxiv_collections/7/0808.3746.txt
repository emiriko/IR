Using the game-theoretic framework for probability, Vovk and Shafer. have
shown that it is always possible, using randomization, to make sequential
probability forecasts that pass any countable set of well-behaved statistical
tests. This result generalizes work by other authors, who consider only tests
of calbration.
  We complement this result with a lower bound. We show that Vovk and Shafer's
result is valid only when the forecasts are computed with unrestrictedly
increasing degree of accuracy.
  When some level of discreteness is fixed, we present a game-theoretic
generalization of Oakes' example for randomized forecasting that is a test
failing any given method of deferministic forecasting; originally, this example
was presented for deterministic calibration.