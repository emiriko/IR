In the thesis we take the split chain approach to analyzing Markov chains and
use it to establish fixed-width results for estimators obtained via Markov
chain Monte Carlo procedures (MCMC). Theoretical results include necessary and
sufficient conditions in terms of regeneration for central limit theorems for
ergodic Markov chains and a regenerative proof of a CLT version for uniformly
ergodic Markov chains with $E_{\pi}f^2< \infty.$ To obtain asymptotic
confidence intervals for MCMC estimators, strongly consistent estimators of the
asymptotic variance are essential. We relax assumptions required to obtain such
estimators. Moreover, under a drift condition, nonasymptotic fixed-width
results for MCMC estimators for a general state space setting (not necessarily
compact) and not necessarily bounded target function $f$ are obtained. The last
chapter is devoted to the idea of adaptive Monte Carlo simulation and provides
convergence results and law of large numbers for adaptive procedures under
path-stability condition for transition kernels.