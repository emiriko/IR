(Abridged) The far-infrared (FIR) and radio luminosities of star-forming
galaxies are linearly correlated over a very wide range in star formation rate,
from normal spirals like the Milky Way to the most intense starbursts. Using
one-zone models of cosmic ray (CR) injection, cooling, and escape in
star-forming galaxies, we attempt to reproduce the observed FIR-radio
correlation over its entire span. We show that ~2% of the kinetic energy from
supernova explosions must go into primary CR electrons and that ~10 - 20% must
go into primary CR protons. Secondary electrons and positrons are likely
comparable to or dominate primary electrons in dense starburst galaxies. We
discuss the implications of our models for the magnetic field strengths of
starbursts, the detectability of starbursts by Fermi, and cosmic ray feedback.
Overall, our models indicate that both CR protons and electrons escape from low
surface density galaxies, but lose most of their energy before escaping dense
starbursts. The FIR-radio correlation is caused by a combination of the
efficient cooling of CR electrons (calorimetry) in starbursts and a conspiracy
of several factors. For lower surface density galaxies, the decreasing radio
emission caused by CR escape is balanced by the decreasing FIR emission caused
by the low effective UV dust opacity. In starbursts, bremsstrahlung,
ionization, and Inverse Compton cooling decrease the radio emission, but they
are countered by secondary electrons/positrons and the decreasing critical
synchrotron frequency, which both increase the radio emission. Our conclusions
hold for a broad range of variations on our fiducial model.