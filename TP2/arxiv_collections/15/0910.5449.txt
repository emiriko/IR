The next generation of telescopes will acquire terabytes of image data on a
nightly basis. Collectively, these large images will contain billions of
interesting objects, which astronomers call sources. The astronomers' task is
to construct a catalog detailing the coordinates and other properties of the
sources. The source catalog is the primary data product for most telescopes and
is an important input for testing new astrophysical theories, but to construct
the catalog one must first detect the sources. Existing algorithms for catalog
creation are effective at detecting sources, but do not have rigorous
statistical error control. At the same time, there are several multiple testing
procedures that provide rigorous error control, but they are not designed to
detect sources that are aggregated over several pixels. In this paper, we
propose a technique that does both, by providing rigorous statistical error
control on the aggregate objects themselves rather than the pixels. We
demonstrate the effectiveness of this approach on data from the Chandra X-ray
Observatory Satellite. Our technique effectively controls the rate of false
sources, yet still detects almost all of the sources detected by procedures
that do not have such rigorous error control and have the advantage of
additional data in the form of follow up observations, which will not be
available for upcoming large telescopes. In fact, we even detect a new source
that was missed by previous studies. The statistical methods developed in this
paper can be extended to problems beyond Astronomy, as we will illustrate with
an example from Neuroimaging.