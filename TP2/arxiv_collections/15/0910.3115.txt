A combined Short-Term Learning (STL) and Long-Term Learning (LTL) approach to
solving mobile robot navigation problems is presented and tested in both real
and simulated environments. The LTL consists of rapid simulations that use a
Genetic Algorithm to derive diverse sets of behaviours. These sets are then
transferred to an idiotypic Artificial Immune System (AIS), which forms the STL
phase, and the system is said to be seeded. The combined LTL-STL approach is
compared with using STL only, and with using a handdesigned controller. In
addition, the STL phase is tested when the idiotypic mechanism is turned off.
The results provide substantial evidence that the best option is the seeded
idiotypic system, i.e. the architecture that merges LTL with an idiotypic AIS
for the STL. They also show that structurally different environments can be
used for the two phases without compromising transferability