It is shown that the $f$-divergence between two probability measures $P$ and
$R$ equals the supremum of the same $f$-divergence computed over all finite
measurable partitions of the original space, thus generalizing results
previously proved by Gel'fand and Yaglom and by Peres for the Information
Divergence and more recently by Dukkipati, Bhatnagar and Murty for the Tsallis'
and Renyi's divergences.