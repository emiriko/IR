Formalism based on GA is an alternative to distributed representation models
developed so far --- Smolensky's tensor product, Holographic Reduced
Representations (HRR) and Binary Spatter Code (BSC). Convolutions are replaced
by geometric products, interpretable in terms of geometry which seems to be the
most natural language for visualization of higher concepts. This paper recalls
the main ideas behind the GA model and investigates recognition test results
using both inner product and a clipped version of matrix representation. The
influence of accidental blade equality on recognition is also studied. Finally,
the efficiency of the GA model is compared to that of previously developed
models.