It is becoming ever clearer that the neutrino signal from the next supernova
in our Galaxy can reveal missing information about the neutrino as well as
allowing us to probe the explosion of the star by decoding the temporal and
spectral evolution of the flavor composition of the signal. But this
information may be lost if turbulence in the supernova `depolarizes' the
neutrinos so that the observed flux for each flavor is an equal mixture of the
initial - unencoded - spectra. Determining if depolarization occurs is one of
the most pressing issues of this field. The most difficult aspect of studying
the effect of turbulence upon the neutrinos is the lack of any theoretical
models that allow us to understand the results of numerical studies. This paper
makes the suggestion that Random Matrix Theory (RMT) may shine some light in
this direction and presents support for this the possibility by comparing the
distribution of crossing and survival probabilities obtained numerically for
some `test case' calculations with the distributions one expects from RMT in
the calculable limit of depolarization of N neutrino flavors.