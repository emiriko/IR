The macroscopic quantum theory of the electromagnetic field in a dielectric
medium interacting with a dense collection of embedded two-level atoms fails to
reproduce a result that is obtained from an application of the classical
Lorentz local-field condition. Specifically, macroscopic quantum
electrodynamics predicts that the Lorentz redshift of the resonance frequency
of the atoms will be enhanced by a factor of the refractive index n of the host
medium. However, an enhancement factor of (n*n+2)/3 is derived using the
Bloembergen procedure in which the classical Lorentz local-field condition is
applied to the optical Bloch equations. Both derivations are short and
uncomplicated and are based on well-established physical theories, yet lead to
contradictory results. Microscopic quantum electrodynamics confirms the
classical local-field-based results. Then the application of macroscopic
quantum electrodynamic theory to embedded atoms is proved false by a specific
example in which both the correspondence principle and microscopic theory of
quantum electrodynamics are violated.