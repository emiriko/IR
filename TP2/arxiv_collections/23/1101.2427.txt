In this paper we compare the use of several features in the task of content
filtering for video social networks, a very challenging task, not only because
the unwanted content is related to very high-level semantic concepts (e.g.,
pornography, violence, etc.) but also because videos from social networks are
extremely assorted, preventing the use of constrained a priori information. We
propose a simple method, able to combine diverse evidence, coming from
different features and various video elements (entire video, shots, frames,
keyframes, etc.). We evaluate our method in three social network applications,
related to the detection of unwanted content - pornographic videos, violent
videos, and videos posted to artificially manipulate popularity scores. Using
challenging test databases, we show that this simple scheme is able to obtain
good results, provided that adequate features are chosen. Moreover, we
establish a representation using codebooks of spatiotemporal local descriptors
as critical to the success of the method in all three contexts. This is
consequential, since the state-of-the-art still relies heavily on static
features for the tasks addressed.