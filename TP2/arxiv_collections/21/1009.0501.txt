Classic evaluation methods of believable agents are time-consuming because
they involve many human to judge agents. They are well suited to validate work
on new believable behaviours models. However, during the implementation,
numerous experiments can help to improve agents' believability. We propose a
method which aim at assessing how much an agent's behaviour looks like humans'
behaviours. By representing behaviours with vectors, we can store data computed
for humans and then evaluate as many agents as needed without further need of
humans. We present a test experiment which shows that even a simple evaluation
following our method can reveal differences between quite believable agents and
humans. This method seems promising although, as shown in our experiment,
results' analysis can be difficult.