Complex networks are mapped to a model of boxes and balls where the balls are
distinguishable. It is shown that the scale-free size distribution of boxes
maximizes the information associated with the boxes provided configurations
including boxes containing a finite fraction of the total amount of balls are
excluded. It is conjectured that for a connected network with only links
between different nodes, the nodes with a finite fraction of links are
effectively suppressed. It is hence suggested that for such networks the
scale-free node-size distribution maximizes the information encoded on the
nodes. The noise associated with the size distributions is also obtained from a
maximum entropy principle. Finally explicit predictions from our least bias
approach are found to be born out by metabolic networks.