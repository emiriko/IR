We consider how an agent should update her uncertainty when it is represented
by a set $\P$ of probability distributions and the agent observes that a random
variable $X$ takes on value $x$, given that the agent makes decisions using the
minimax criterion, perhaps the best-studied and most commonly-used criterion in
the literature. We adopt a game-theoretic framework, where the agent plays
against a bookie, who chooses some distribution from $\P$. We consider two
reasonable games that differ in what the bookie knows when he makes his choice.
Anomalies that have been observed before, like time inconsistency, can be
understood as arising important because different games are being played,
against bookies with different information. We characterize the important
special cases in which the optimal decision rules according to the minimax
criterion amount to either conditioning or simply ignoring the information.
Finally, we consider the relationship between conditioning and calibration when
uncertainty is described by sets of probabilities.